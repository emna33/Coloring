{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"aborted","timestamp":1683917431415,"user":{"displayName":"EMNA KAMMOUN","userId":"01460099683938367963"},"user_tz":-120},"id":"61TlQhudzePC"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20,"status":"aborted","timestamp":1683917431416,"user":{"displayName":"EMNA KAMMOUN","userId":"01460099683938367963"},"user_tz":-120},"id":"-ZZIDYQvWfSJ"},"outputs":[],"source":["%cd /content/gdrive/MyDrive"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1683917431417,"user":{"displayName":"EMNA KAMMOUN","userId":"01460099683938367963"},"user_tz":-120},"id":"JT8HBmaGWzu3"},"outputs":[],"source":["%cd Coloring"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20,"status":"aborted","timestamp":1683917431417,"user":{"displayName":"EMNA KAMMOUN","userId":"01460099683938367963"},"user_tz":-120},"id":"mN98LL7DXnj7"},"outputs":[],"source":["%cd Full-version"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":10413,"status":"ok","timestamp":1683917343102,"user":{"displayName":"EMNA KAMMOUN","userId":"01460099683938367963"},"user_tz":-120},"id":"7m6RyQaNW64d"},"outputs":[],"source":["import keras\n","from keras.applications.inception_resnet_v2 import InceptionResNetV2\n","from keras.preprocessing import image\n","from keras.layers import Layer\n","from keras.applications.inception_resnet_v2 import preprocess_input\n","from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape,concatenate\n","from keras.layers import Activation, Dense, Dropout, Flatten\n","from tensorflow.keras.layers import BatchNormalization\n","from keras.callbacks import TensorBoard \n","from keras.models import Sequential, Model\n","from keras.layers.core import RepeatVector, Permute\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n","from skimage.transform import resize\n","from skimage.io import imsave\n","import numpy as np\n","import os\n","import random\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":22327,"status":"ok","timestamp":1683917365423,"user":{"displayName":"EMNA KAMMOUN","userId":"01460099683938367963"},"user_tz":-120},"id":"9QHRoArPW8jj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a630dea3-c549-49bc-c277-cd6a6f2c0132"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n","225209952/225209952 [==============================] - 9s 0us/step\n"]}],"source":["# Get images\n","X = []\n","for filename in os.listdir('Train/'):\n","  if not filename.startswith('.'):  # ignore hidden files and directories\n","    X.append(img_to_array(load_img('Train/'+filename)))\n","X = np.array(X, dtype=float)\n","Xtrain = 1.0/255*X\n","#Load weights\n","inception = InceptionResNetV2(weights='imagenet', include_top=True)\n","# inception.graph = tf.get_default_graph()\n","inception = Model(inputs=inception.input, outputs=inception.output)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1295,"status":"ok","timestamp":1683917366706,"user":{"displayName":"EMNA KAMMOUN","userId":"01460099683938367963"},"user_tz":-120},"id":"uDRt1-kW9Mg_"},"outputs":[],"source":["from PIL import Image\n","import os\n","\n","# Chemin du dossier contenant les images à redimensionner\n","input_folder = \"Train\"\n","\n","# Chemin du dossier où enregistrer les images redimensionnées\n","output_folder = \"Train\"\n","\n","# Nouvelle taille pour les images redimensionnées\n","new_size = (256, 256)\n","\n","# Parcourir toutes les images dans le dossier d'entrée\n","for filename in os.listdir(input_folder):\n","    # Vérifier que le fichier est une image\n","    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n","        # Charger l'image\n","        image = Image.open(os.path.join(input_folder, filename))\n","\n","        # Redimensionner l'image\n","        new_image = image.resize(new_size)\n","\n","        # Enregistrer l'image redimensionnée dans le dossier de sortie\n","        new_image.save(os.path.join(output_folder, filename))"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":22677,"status":"ok","timestamp":1683917389380,"user":{"displayName":"EMNA KAMMOUN","userId":"01460099683938367963"},"user_tz":-120},"id":"efmsC-7F9dnm"},"outputs":[],"source":["from PIL import Image\n","import os\n","\n","# Chemin du dossier contenant les images à redimensionner\n","input_folder = \"Test\"\n","\n","# Chemin du dossier où enregistrer les images redimensionnées\n","output_folder = \"Test\"\n","\n","# Nouvelle taille pour les images redimensionnées\n","new_size = (256, 256)\n","\n","# Parcourir toutes les images dans le dossier d'entrée\n","for filename in os.listdir(input_folder):\n","    # Vérifier que le fichier est une image\n","    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n","        # Charger l'image\n","        image = Image.open(os.path.join(input_folder, filename))\n","\n","        # Redimensionner l'image\n","        new_image = image.resize(new_size)\n","\n","        # Enregistrer l'image redimensionnée dans le dossier de sortie\n","        new_image.save(os.path.join(output_folder, filename))"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1683917389382,"user":{"displayName":"EMNA KAMMOUN","userId":"01460099683938367963"},"user_tz":-120},"id":"npmpCEBh9oZO"},"outputs":[],"source":["embed_input = Input(shape=(1000,))\n","\n","#Encoder\n","encoder_input = Input(shape=(256, 256, 1,))\n","encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n","encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n","encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n","encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n","encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n","encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n","encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n","encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n","\n","#Fusion\n","fusion_output = RepeatVector(32 * 32)(embed_input) \n","fusion_output = Reshape(([32, 32, 1000]))(fusion_output)\n","fusion_output = concatenate([encoder_output, fusion_output], axis=3) \n","fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output) \n","\n","#Decoder\n","decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n","decoder_output = UpSampling2D((2, 2))(decoder_output)\n","decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n","decoder_output = UpSampling2D((2, 2))(decoder_output)\n","decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n","decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n","decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n","\n","decoder_output = UpSampling2D((2, 2))(decoder_output)\n","\n","model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1683917389383,"user":{"displayName":"EMNA KAMMOUN","userId":"01460099683938367963"},"user_tz":-120},"id":"chqnEV5g9896"},"outputs":[],"source":["def create_inception_embedding(grayscaled_rgb):\n","    grayscaled_rgb_resized = []\n","    for i in grayscaled_rgb:\n","        i = resize(i, (299, 299, 3), mode='constant')\n","        grayscaled_rgb_resized.append(i)\n","    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n","    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n","    # with inception.graph.as_default():\n","    #     embed = inception.predict(grayscaled_rgb_resized)\n","    # return embed\n","    with tf.GradientTape() as tape:\n","        embed = inception(grayscaled_rgb_resized)\n","    \n","    return embed\n","\n","# Image transformer\n","datagen = ImageDataGenerator(\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        rotation_range=20,\n","        horizontal_flip=True)\n","\n","#Generate training data\n","batch_size = 10\n","\n","def image_a_b_gen(batch_size):\n","    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n","        grayscaled_rgb = gray2rgb(rgb2gray(batch))\n","        embed = create_inception_embedding(grayscaled_rgb)\n","        lab_batch = rgb2lab(batch)\n","        X_batch = lab_batch[:,:,:,0]\n","        X_batch = X_batch.reshape(X_batch.shape+(1,))\n","        Y_batch = lab_batch[:,:,:,1:] / 128\n","        yield ([X_batch, create_inception_embedding(grayscaled_rgb)], Y_batch)\n","\n","\n","#Train model      \n","#model.compile(optimizer='rmsprop', loss='mse')\n","#model.fit_generator(image_a_b_gen(batch_size), epochs=6, steps_per_epoch=10)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"e5E1Tjxz-O3U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683919935696,"user_tz":-120,"elapsed":45749,"user":{"displayName":"EMNA KAMMOUN","userId":"01460099683938367963"}},"outputId":"32c03563-b113-4b5b-ce99-98016caba353"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 11s 11s/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"]}],"source":["color_me = []\n","for filename in os.listdir('Test/'):\n","    color_me.append(img_to_array(load_img('Test/'+filename)))\n","color_me = np.array(color_me, dtype=float)\n","gray_me = gray2rgb(rgb2gray(1.0/255*color_me))\n","color_me_embed = create_inception_embedding(gray_me)\n","color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n","color_me = color_me.reshape(color_me.shape+(1,))\n","\n","\n","# Test model\n","output = model.predict([color_me, color_me_embed])\n","output = output * 128\n","from sklearn.metrics import mean_squared_error\n","\n","# Output colorizations\n","for i in range(len(output)):\n","    cur = np.zeros((256, 256, 3))\n","    cur[:,:,0] = color_me[i][:,:,0]\n","    cur[:,:,1:] = output[i]\n","    imsave(\"result/img_\"+str(i)+\".png\", lab2rgb(cur))\n","\n","   \n","\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}